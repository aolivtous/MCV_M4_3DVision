{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa4daf0-04ce-4fe8-8780-46e09d239f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sqlite3\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from visualize_model import Model\n",
    "from database import blob_to_array, pair_id_to_image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c31494-3050-4951-aed1-b463f3fba821",
   "metadata": {},
   "source": [
    "# 2. Analyze reconstructions using python\n",
    "## 2.1. Run the notebook, using the Gerrard Hall reconstruction (0.5)\n",
    "#### <span style='color:Green'> - Add the path to your reconstruction. Answer the questions at the end  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41796fd2-2304-487f-a74c-3f1a51ad83f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guillem/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your path\n",
    "# Get the path of the current notebook\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "# Cut the current path until the folder \"M4_Project\"\n",
    "current_path = current_path[:current_path.find(\"M4_Project\")]\n",
    "current_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728fbbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guillem/gerrard-hall/reconstruction\n",
      "/home/guillem/gerrard-hall/database.db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reconstruction_path = current_path + \"gerrard-hall/reconstruction\"\n",
    "database_path = current_path + \"gerrard-hall/database.db\"\n",
    "print(reconstruction_path)\n",
    "print(database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a701bb3-945a-434c-880c-849dad97a97d",
   "metadata": {},
   "source": [
    "#### Load an existing reconstruction and print its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf644962-ba41-403f-a1a4-3e1b08d16151",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/guillem/gerrard-hall/reconstruction/cameras.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m Model()\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mread_model(reconstruction_path, ext\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.bin\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# Should also work with .txt\u001b[39;00m\n",
      "File \u001b[0;32m~/M4_Project/lab5/visualize_model.py:45\u001b[0m, in \u001b[0;36mModel.read_model\u001b[0;34m(self, path, ext)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_model\u001b[39m(\u001b[39mself\u001b[39m, path, ext\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcameras, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoints3D \u001b[39m=\u001b[39m read_model(path, ext)\n",
      "File \u001b[0;32m~/M4_Project/lab5/read_write_model.py:435\u001b[0m, in \u001b[0;36mread_model\u001b[0;34m(path, ext)\u001b[0m\n\u001b[1;32m    433\u001b[0m     points3D \u001b[39m=\u001b[39m read_points3D_text(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mpoints3D\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m ext)\n\u001b[1;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     cameras \u001b[39m=\u001b[39m read_cameras_binary(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, \u001b[39m\"\u001b[39;49m\u001b[39mcameras\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m ext))\n\u001b[1;32m    436\u001b[0m     images \u001b[39m=\u001b[39m read_images_binary(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mimages\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m ext))\n\u001b[1;32m    437\u001b[0m     points3D \u001b[39m=\u001b[39m read_points3D_binary(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mpoints3D\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m ext)\n",
      "File \u001b[0;32m~/M4_Project/lab5/read_write_model.py:134\u001b[0m, in \u001b[0;36mread_cameras_binary\u001b[0;34m(path_to_model_file)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39msee: src/base/reconstruction.cc\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m    void Reconstruction::WriteCamerasBinary(const std::string& path)\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    void Reconstruction::ReadCamerasBinary(const std::string& path)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m cameras \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 134\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path_to_model_file, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m    135\u001b[0m     num_cameras \u001b[39m=\u001b[39m read_next_bytes(fid, \u001b[39m8\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mQ\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_cameras):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/guillem/gerrard-hall/reconstruction/cameras.bin'"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.read_model(reconstruction_path, ext='.bin') # Should also work with .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629e852-0407-4eff-ba62-b9d1d51015bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = model.images\n",
    "cameras = model.cameras\n",
    "points3D = model.points3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47fb58-dbcd-4c6f-8168-e296832aacf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(images)} images. This is the information available for one of them:\")\n",
    "print(images[1])\n",
    "print(f\"\\nLoaded {len(cameras)} cameras. This is the information available for one of them:\")\n",
    "print(cameras[1])\n",
    "print(f\"\\nLoaded {len(points3D)} 3D points. This is the information available for one of them:\")\n",
    "print(points3D[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce97039-6c3e-40e9-af81-e0795fc5b41a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d1dde-024f-47b6-85cc-99f0801f414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ff5d3-a33f-41f5-882d-d370bf3dd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = dict(\n",
    "        (image_id, blob_to_array(data, np.float32, (-1, 2)))\n",
    "        for image_id, data in db.execute(\n",
    "            \"SELECT image_id, data FROM keypoints\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843a569-d812-4bfe-8f61-e68cc9d9dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded keypoints from {len(keypoints)} images. These are the {len(keypoints[1])} keypoints for one of them:\")\n",
    "print(keypoints[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f31f2a-d3b3-48af-b0cc-1276f5cfe177",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = dict()\n",
    "count_no_data = 0\n",
    "for pair_id, data in db.execute(\"SELECT pair_id, data FROM matches\"):\n",
    "    if data is None:\n",
    "        count_no_data += 1\n",
    "    else:\n",
    "        matches[pair_id_to_image_ids(pair_id)] = blob_to_array(data, np.uint32, (-1, 2))\n",
    "print(f\"Loaded {len(matches)} matches. {count_no_data}/{len(matches)+count_no_data} matches contained no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07761b-eaec-488d-b1e9-36720e203a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"These are the matches between two images:\")\n",
    "print(matches[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c0675-6841-4519-b79f-cc2b811b94fd",
   "metadata": {},
   "source": [
    "#### Visualize the point cloud and cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95e07c-b1d6-4f08-8842-8fc41b676a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_window()\n",
    "model.add_points()\n",
    "model.add_cameras(scale=0.25)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d5e272-83de-4136-b047-885051bd7e78",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'>  How many keypoints there are in total? </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c13142-d04b-4f48-9b28-5e78b9c72a8b",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'>  How many 3D points originated from a keypoint in the first image? </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a83ca-0ad4-493f-a7b7-9e11ae8153c0",
   "metadata": {},
   "source": [
    "## 2.2 Plot the 3D points coloured according to the number of images and error. (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803fb41-cb01-43c2-9853-9f4458640a75",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'> - Plot the 3D points coloured according to the **number of images** from which it originated. </span> Can you extract any conclusions from the visualization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d55db2-d7b4-4eda-91c2-8b2001fbf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba4033-e370-45e0-9dcd-2964d3c5763a",
   "metadata": {},
   "source": [
    "#### <span style='color:Green'> - Plot the 3D points coloured according to the **error**. </span> - What is this parameter? Can you extract any conclusions from the visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb29f94-1864-4e21-b534-7eb681dd9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe177d5-893b-41b4-aa1c-6d6fb06b54b7",
   "metadata": {},
   "source": [
    "## 2.3 Plot the 3D points that correspond to a keypoint in the first image. Also plot the image with the keypoints (1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888156a-c5f5-4695-a75b-2883f1a7c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117ea99-bc47-41f6-8b14-a42213ee0482",
   "metadata": {},
   "source": [
    "## 2.4 Create a visualization for the number of matches between all images. (1.0)\n",
    "For example: https://seaborn.pydata.org/generated/seaborn.heatmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fba504-a871-4287-9833-46aa1c883637",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab06d62-e966-439e-87d7-5d7ba973bca1",
   "metadata": {},
   "source": [
    "## 2.5 Visualize the keypoints and matches between the two images used in lab 4 using Colmap, how it compares to the results from lab 4? (1.0)\n",
    "#### <span style='color:Green'> You can use the GUI to get the keypoints and matches and then visualize it here, following the same style as in lab 4 to get comparable results. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cc03b-672c-491c-bd61-e40bcc757f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a4a42-5c40-4983-af8a-2c0ef286ce5d",
   "metadata": {},
   "source": [
    "## 2.6 Triangulate and visualize the 3D points from the keypoints extracted using Colmap on the two images used in lab 4, how it compares to the results from lab 4? (1.0) \n",
    "#### <span style='color:Green'> - Use the triangulation from lab 4 to the get the 3D points and visualize them following the same style. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc66ad-ab36-4192-b93b-8523adfb3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eacbca-842d-4d9e-85bd-efc35c5dd15a",
   "metadata": {},
   "source": [
    "## 2.7 Visualize the sparse reconstruction using the 2 images from lab 4, and the complete CASTLE dataset. Comment on the differences between techniques and number of images used. (1.0)\n",
    "#### <span style='color:Green'> - Use the reconstruction from Colmap to the get the 3D points and visualize them following the same style, using two images and the complete dataset. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9504a3-dcbf-4b2b-9ff6-71c5a4584742",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO 2.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "cbc8b86dd1e4076894a7e7b19a26d193e02924e2a2af9fd4b928c9519092ea8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
